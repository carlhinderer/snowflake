-----------------------------------------------------------------------
| CHAPTER 3 - CREATING AND MANAGING DATABASE OBJECTS                  |
-----------------------------------------------------------------------

- Database Basics

    - Within Snowflake, all data is stored in database tables.  Tables are logically structured into rows
        and columns.  


    - All the objects discussed in this chapter are 'securable database objects'.  A Snowflake securable
        object is an entity for which you grant access to specific roles.  Roles, which have been granted
        access privileges, are assigned to users.  A User can be either a person or application.



- Prep Work

    - Create a new worksheet called 'Chapter3 Creating Database Objects'.

    - We should be using the 'SYSADMIN' role and the 'COMPUTE_WH' database, which we'll create now.



- Creating and Managing Snowflake Databases

    - In Snowflake, a database logically groups data, while the schema organizes it.  Together, the 
        database and schema comprise the namespace.  Whenever we work with db objects, we'll need to specify
        a namespace, unless the db and schema we want to use are the active context in the workspace.

      If the database or schema needs to be specified, we include the USE command.


    - We can create either 'permanent' or 'transient' databases.  Transient databases have a maximum
        one-day retention period (aka 'Time Travel period').


    - The Snowflake Time Travel period is the time during which table data can be queried at a historical
        point in time.  The default time travel period is one day, but it can be up to 90 days for
        permanent databases.  The Time Travel period can also be set to 0 days if the property is not
        desired.


    - Snowflake's 'fail-safe data recovery' service provides a 7-day retention period during which
        data from permanent dbs and db objects may be recoverable.  

        - The fail-safe recovery period is 7 days after the data retention period ends.  

        - Unlike time-travel data, fail-safe data is only recoverable by Snowflake employees.

        - Data storage costs are incurred for those 7 days, which is a consideration when deciding what type
            of database to create.


    - The basic SQL commands for dbs are:

        CREATE DATABASE
        ALTER DATABASE
        DROP DATABASE
        SHOW DATABASE


    - The CREATE DATABASE command is used to:

        - Create a new database
        - Clone an existing database
        - Create a database from a share provided by another Snowflake account
        - Create a replica of an existing primary database


    - We can create a database either with the UI or the SQL command.  We'll start by creating one with the
        UI.

        > Add Database

            Name: DEMO3A_DB 
            Comment: Permanent database for Chapter 3 Exercises


    - Now, we'll create another database, but this time we'll use SQL in the worksheet:

        USE ROLE SYSADMIN;
        USE WAREHOUSE COMPUTE_WH;
        CREATE OR REPLACE TRANSIENT DATABASE DEMO3B_DB
        Comment = 'Transient Database for Chapter 3 Exercises';


    - Note that CREATE OR REPLACE should be used sparingly in Production, since it will overwrite an existing
        database.  We should use CREATE IF NOT EXISTS instead.


    - Whenever we create a new database, it is automatically set as the active database for the current
        session.  To use a different database, we need to switch the context using USE DATABASE.


    - As SYSADMIN, we'll see the 2 databases we just created, plus the 'SNOWFLAKE_SAMPLE_DATA' that
        automatically comes with the Snowflake account.

      If we switch to ACCOUNTADMIN, we'll see an addtional database called 'SNOWFLAKE'.

        USE ROLE ACCOUNTADMIN;
        SHOW DATABASES;


    - Note that all databases, including the ones we just created, have a one-day retention time.  This
        specifies the the number of days for which the underlying data is retained after deletion, and for
        which CLONE and UNDROP commands can be performed on the db.

      We can change the retention time for permanent databases, but not for transient ones.

        USE ROLE SYSADMIN;
        ALTER DATABASE DEMO3A_DB
        SET DATA_RETENTION_TIME_IN_DAYS=10;


    - We can create transient tables within a permanent db, but we cannot create permanent tables within a
        transient db.  Here, we'll create a table in our transient db:

        USE ROLE SYSADMIN;
        CREATE OR REPLACE TABLE DEMO3B_DB.PUBLIC.SUMMARY
          (CASH_AMT number,
           RECEIVABLES_AMT number,
           CUSTOMER_AMT number);


    - The SNOWFLAKE db is owned by Snowflake, and is a system-defined, read-only, shared db that provides
        object metadata and usage metrics about your account.  It cannot be deleted from your account,
        and does not result in storage charges.

      We'll be using the SNOWFLAKE_SAMPLE_DATA db in exercises in this chapter.  It is a shared db that
        anyone can access.  We don't incur storage costs for it, but we will incur compute costs if we run 
        queries on it.



- Creating and Managing Snowflake Schemas

    - When we create a schema, we need to specify which db we want to use.  We can use either of these 2
        commands to create a schema, they'll do the same thing:

        -- This will create a schema
        USE ROLE SYSADMIN; USE DATABASE DEMO3A_DB;
        CREATE OR REPLACE SCHEMA BANKING;

        -- This will also create a schema
        USE ROLE SYSADMIN;
        CREATE OR REPLACE SCHEMA DEMO3A_DB.BANKING;


    - Since our db has a retention time of 10 days, our schema will also.  However, we can change this on
        a per-schema basis:

        USE ROLE SYSADMIN;
        ALTER SCHEMA DEMO3A_DB.BANKING
        SET DATA_RETENTION_TIME_IN_DAYS=1;

        SHOW SCHEMAS;


    - In the previous section, we created a 'SUMMARY' table in the 'DEMO3B_DB.PUBLIC' schema.  Now, we
        decide we want the table to exist in a different schema.  We'll create the new schema, then
        rename the table.

        USE ROLE SYSADMIN;
        CREATE OR REPLACE SCHEMA DEMO3B_DB.BANKING;
        ALTER TABLE DEMO3B_DB.PUBLIC.SUMMARY
        RENAME TO DEMO3B_DB.BANKING.SUMMARY;


    - Just like db, schemas can either be permanent or transient (permanent is the default).  However, for
        schemas, we also have 'managed access schemas'.  In a managed access schema, the schema owner 
        manages grants on the object within a schema (ie table or view), but doesn't have USAGE, SELECT,
        or DROP privileges on the objects.

      To create a schema with managed access:

        USE ROLE SYSADMIN; USE DATABASE DEMO3A_DB;
        CREATE OR REPLACE SCHEMA MSCHEMA WITH MANAGED ACCESS;

        -- Now, we can see the MANAGED ACCESS option set
        SHOW SCHEMAS;


    - There are 2 database schemas that are always included in every database that is created:
        INFORMATION_SCHEMA and PUBLIC.  The PUBLIC schema is the default schema, and can be used to create
        any other objects.

      The INFORMATION_SCHEMA is a special schema for the system that contains views and table functions
        which provide access to the db and account metadata.



- INFORMATION_SCHEMA

    - The INFORMATION_SCHEMA is aka the 'Data Dictionary', and includes metadata about the objects in the
        database, as well as account-level objects such as roles.


    - More than 20 system-defined views are included.  These views can be divided into 2 categories:
        account views and database views.  Account views include:

        APPLICABLE_ROLES                  # One role for each role grant
        DATABASES                         # One row for each db defined in your account
        ENABLED_ROLES                     # One row for each currently enabled row in the session
        INFORMATION_SCHEMA_CATALOG_NAME   # Name of the db where the INFORMATION_SCHEMA resides
        LOAD_HISTORY                      # One row for each file loaded into tables using COPY TO
        REPLICATION_DATABASES             # One row for each primary and secondary db (for replication)


    - To look at what is in each of these views (Note since they are account-level, they'll always return
        the same results):

        -- These return the same results
        SELECT * FROM SNOWFLAKE_SAMPLE_DATA.INFORMATION_SCHEMA.DATABASES;
        SELECT * FROM DEMO3A_DB.INFORMATION_SCHEMA.DATABASES;

        -- These also return the same results
        SELECT * FROM SNOWFLAKE_SAMPLE_DATA.INFORMATION_SCHEMA.APPLICABLE_ROLES;
        SELECT * FROM DEMO3A_DB.INFORMATION_SCHEMA.APPLICABLE_ROLES;


    - Some of the database views include:

        COLUMNS                     # One row for each column in tables defined in db
        EXTERNAL_TABLES             # One row for each external table in the db
        FILE_FORMATS                # One row for each file format defined in the db
        FUNCTIONS                   # One row for each UDF in the db
        OBJECT_PRIVILEGES           # One row for each access privilege granted in the db
        PIPES                       # One row for each pipe defined in the db
        PROCEDURES                  # One row for each stored procedure defined in the db
        REFERENTIAL_CONSTRAINTS     # One row for each referential integrity constraint defined in the db
        SCHEMATA                    # One row for each schema defined in the db
        SEQUENCES                   # One row for each stage defined in the db
        STAGES                      # One row for each stage defined in the db
        TABLE_CONSTRAINTS           # One row for each table constraint defined in the db
        TABLE_PRIVILEGES            # One row for each table privilege granted to each role in the db
        TABLE_STORAGE_METRICS       # Displays table-level storage utilization information
        TABLES                      # One row for each table and view in the db
        USAGE_PRIVILEGES            # One row for each privilege defined for sequences in the db
        VIEWS                       # One row for each view in the db


    - There are different ways to look at database-specific metadata.  For instance, these will both show
        you the schemas, although the INFORMATION_SCHEMA method provides more information:

        SELECT * FROM SNOWFLAKE_SAMPLE_DATA.INFORMATION_SCHEMA.SCHEMATA;

        SHOW SCHEMAS IN DATABASE SNOWFLAKE_SAMPLE_DATA;


    - To look at table privileges:

        -- Empty since we didn't create any tables yet
        SELECT * FROM DEMO3A_DB.INFORMATION_SCHEMA.TABLE_PRIVILEGES;

        -- Has one row for the table we created
        SELECT * FROM DEMO3B_DB.INFORMATION_SCHEMA.TABLE_PRIVILEGES;



- ACCOUNT_USAGE Schema

    - The SNOWFLAKE db, viewable by the ACCOUNTADMIN by default, includes an ACCOUNT_USAGE schema that is
        very similar to INFORMATION_SCHEMA.  However, there are 3 differences:

        1. The ACCOUNT_USAGE schema includes records for dropped objects

        2. The ACCOUNT_USAGE schema has a longer retention time for historical data (one year)

        3. Most views in the INFORMATION_SCHEMA have no latency, but the latency time for the ACCOUNT_USAGE 
             schema can be up to 1-2 hours for some views.


    - One of the common uses for ACCOUNT_USAGE is to keep track of credits used over time by each VW in
        your account (month-to-date):

        USE ROLE ACCOUNTADMIN; USE DATABASE SNOWFLAKE; USE SCHEMA ACCOUNT_USAGE;
        USE WAREHOUSE COMPUTE_WH;

        SELECT start_time::date AS USAGE_DATE, WAREHOUSE_NAME,
        SUM(credits_used) AS TOTAL_CREDITS_CONSUMED
        FROM warehouse_metering_history
        WHERE start_time >= date_trunc(Month, current_date)
        GROUP BY 1,2
        ORDER BY 2,1;



- Creating and Managing Snowflake Tables

    - All Snowflake data is stored in tables.  In addition to permanent and transient tables, there are
        also hybrid, temporary, and external tables.

        - Hybrid tables support the new Unistore workload (described in Ch 12).

        - Temporary tables only exist in the session in which they are created, and are commonly used for ETL.

        - External tables give you the ability to directly process or query data that exists elsewhere
            without ingesting it into Snowflake, including data that lives in a data lake.


    - One way you can work with your external data is by integrating Apache Hive metastores with Snowflake.
        You can use the new Hive Metastore connector to connect to your Hadoop environments.  Snowflake
        support is also available if you use new technologies like Delta Lake or Apache Iceberg.


    - In June 2022, Snowflake introduced a new table type, 'materialized tables'.  Materialized tables allow
        users to declaratively specify the pipelines where transformations can occur.  Snowflake then
        handles the incremental refresh to materialize the data.

      In this way, Snowflake materialized tables automatically refresh as new data streams in.  This can be
        thought of as the logical progression of streams.


    - Like with databases and schemas, we can use the CREATE, ALTER, DROP, and SHOW TABLES commands.  Also,
        we'll use INTERT INTO or COPY INTO to place data in tables.  

      For tables we create, we can also use TRUNCATE or DELETE to remove data from a table.  TRUNCATE also
        clears table load history metadata, while DELETE retains the metadata.


    - Transient tables have characteristics of both permanent and temporary tables.  They are designed for
        transitory data that needs to be maintained beyond a session but doesn't need the same level of
        data recovery as permanent tables.  The storage costs are lower.


    - Transient tables cannot be converted to permanent, and permanent tables cannot be converted to
        transient, because this is set at table creation time.


    - Now, we'll create some tables that will be used later in the chapter.

        USE ROLE SYSADMIN; USE DATABASE DEMO3A_DB;
        CREATE OR REPLACE SCHEMA BANKING;

        CREATE OR REPLACE TABLE CUSTOMER_ACCT
        (Customer_Account int, Amount int, transaction_ts timestamp);

        CREATE OR REPLACE TABLE CASH
        (Customer_Account int, Amount int, transaction_ts timestamp);

        CREATE OR REPLACE TABLE RECEIVABLES
        (Customer_Account int, Amount int, transaction_ts timestamp);


    - Now, the active role is 'SYSADMIN', the active database is 'DEMO3A_DB', and the active schema is
        'BANKING'.  If we create a new table, it will be located in the 'BANKING schema':

        -- Create new table
        CREATE OR REPLACE TABLE NEWTABLE
        (Customer_Account int, Amount int, transaction_ts timestamp);

        -- Drop table
        DROP TABLE DEMO3A_DB.BANKING.NEWTABLE;



- Creating and Managing Views

    - Along with tables, views are the primary objects maintained in database schemas.  There are 2 types
        of views: materialized and nonmaterialized.  The default type is nonmaterialized.


    - A view is a virtual table created by a query expression.  To create a view by selecting one column
        from Snowflake sample data:

        CREATE OR REPLACE VIEW DEMO3B_DB.PUBLIC.NEWVIEW AS
        SELECT CC_NAME
        FROM (SELECT * FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.CALL_CENTER);


    - Views are useful for showing subsets of tables, which is often for security purposes.


    - To create a materialized view:

        CREATE OR REPLACE MATERIALIZED VIEW DEMO3B_DB.PUBLIC.NEWVIEW_MVW AS
        SELECT CC_NAME
        FROM (SELECT * FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.CALL_CENTER);


    - To see the views that have been created:

        -- Show both nonmaterialized and materialized views
        USE SCHEMA DEMO3B_DB.PUBLIC;
        SHOW VIEWS;

        -- Show materialized views only
        SHOW MATERIALIZED VIEWS;


    - Materialized views get periodically refreshed with data from the base table.  They are generally used
        to aggregate as well as filter data so that the results of resource-intensive operations can be
        stored for improved data performance.  This especially helps if the same query is used frequently.

      Snowflake uses a background service to automatically update materialized views.  As a result, the
        data accessed through materialized views is always current.


    - To illustrate this, we'll create a materialized view.  We'll also create a nonmaterialized view for
        comparison:

        -- Materialized view
        CREATE OR REPLACE MATERIALIZED VIEW DEMO3B_DB.BANKING.SUMMARY_MVW AS
        SELECT * FROM (SELECT * FROM DEMO3B_DB.BANKING.SUMMARY);

        -- Nonmaterialized view
        CREATE OR REPLACE VIEW DEMO3B_DB.BANKING.SUMMARY_VW AS
        SELECT * FROM (SELECT * FROM DEMO3B_DB.BANKING.SUMMARY);


    - As a general rule, it is better to use a nonmaterialized view when the results of the view change
        frequently and the query isn't so expensive and complex to rerun.

        - Regular views incur compute costs but not storage costs
        - Need to way compute costs vs storage costs
        - Materialized views are better for expensive queries that don't change much
        - Materialized views can only query a single table, joins aren't supported



- Snowflake Stages: File Format Included

    - There are 2 types of Snowflake stages: internal and external.  'Stages' are Snowflake objects that
        point to a storage location, either internal to Snowflake or on external cloud storage.


    - Internal stage objects can be either 'named stages' or a 'user stage' or 'table stage'.  The
        'temporary' keyword can be used to create a session-based stage object.


    - In most cases, the storage is permanent, while the stage object (a pointer to the storage location)
        can be temporary or dropped at any time.  Stages are often used as an intermediate step to load
        files to Snowflake tables or unload data from tables into files.


    - Outside locations, such as AWS S3 buckets, Google Cloud Storage buckets, or Azure containers, can 
        be used in external stages.


    - Each user has a stage for storing files which is accessible only by that user (referenced by @~).
        Each Snowflake table has a stage allocated for storing files (referenced by @%<tablename>).

        -- List user stages
        ls@~

        OR

        LIST @~;


    - User and table stages cannot be altered or dropped, and table stages do not support transforming
        data while loading it.


    - Internal named stages and external stages can also be created either as permanent or temporary
        storage.  They are database objects, so they can be used by any user with the appropriate privileges.

        - When a temporary external stage is dropped, the external data is unaffected.

        - When a temporary internal stage is dropped, the data and stage are both dropped, and the files
            are not recoverable.


    - When using stages, we can use file formats to store all the format information we need from loading
        data from files into tables.  The default file format is CSV.  However, we can also create file
        formats for JSON, Avro, Parquet, ORC, and XML.


    - Here is a very basic file format for loading JSON data into a stage:

        USE ROLE SYSADMIN; USE DATABASE DEMO3B_DB;
        CREATE OR REPLACE FILE FORMAT FF_JSON TYPE = JSON;


    - Once we have created the file format, we can use it to create an internal named stage:

        USE DATABASE DEMO3B_DB; USE SCHEMA BANKING;
        CREATE OR REPLACE TEMPORARY STAGE BANKING_STG FILE_FORMAT = FF_JSON;


    - The data is always encrypted, whether in flight to an internal named stage or at rest while stored
        in a Snowflake database table.



- Extending SQL with Stored Procedures and UDFs

    - To extend SQL capabilities, you can create stored procedures and UDFs to acieve functionality not
        possible with Snowflake's built-in functions.

      Both stored procedures and UDFs encapsulate and return a single value.  UTFs can return multiple values 
        (tabular) whereas stored procedures can only return a single value.


    - You can create stored functions in JavaScript, and UDFS in SQL, Javascript, Python, or Java.


    - Both stored procedures and UDFs extend SQL capabilities, but there are many differences between the 2.

        - If you want to perform a db operation such as SELECT, DELETE, or CREATE, you'll need to use a
            stored procedure.

        - If you want to use a function as part of your SQL expression, or if your output needs to include
            a value for each input row, you'll want to use a Snowflake UDF.

        - A UDF is called as part of the SQL statement, but a stored procedure cannot be called in a SQL
            statement.  It is an independent statement called using the CALL statement.

        - A UDF is required to return a value, while a stored procedure is not.



- Example - UDF

    - Python UDFs can only return scalar results, while JS, Java, or SQL UDFs can return either scalar or
        tabular results.

        - A SQL UDF evaluates SQL statement and can refer to other UDFs

        - A JS UDF is useful for manipulating JSON data, and can refer to itself recursively, but you
            cannot import external libraries


    - To get the JS types that we can use in our UDFs:

        -- Get available JS Properties
        CREATE OR REPLACE DATABASE DEMO3C_DB;

        CREATE OR REPLACE FUNCTION JS_PROPERTIES()
        RETURNS string LANGUAGE JAVASCRIPT AS
        $$ return Object.getOwnPropertyNames(this); $$;

        SELECT JS_PROPERTIES();


    - For our first example, here is a standard factorial calculation:

        USE ROLE SYSADMIN; USE DATABASE DEMO3C_DB;
        CREATE OR REPLACE FUNCTION FACTORIAL(n variant)
        RETURNS variant LANGUAGE JAVASCRIPT AS
            'var f=n;
            for (i=n-1; i>0; i--) {
                f=f*i
            }
            return f';

        -- Call the function
        SELECT FACTORIAL(5);

        -- This will error out, since there are size and depth limitations
        SELECT FACTORIAL(50);


    - It is also possible to create secure UDFs, which are the same as regular UDFs, but they hid the DDL
        from the consumer of the UDF and can be shared.



- Example - Secure SQL UDTF That Returns Tabular Value (Market Basket Analysis Example)

    - Market basket analysis is a common use of secure SQL UDFs.  In our example, we want to see how many
        times other items were sold with a particular item.


    - Since we don't want the consumer account to have access to our raw sales data, we'll wrap the SQL
        statement in a secure UDF and create an input parameter.  For our sales data, we'll select a 
        subset of 100,000 rows from the Snowflake sample database.

        CREATE OR REPLACE DATABASE DEMO3D_DB;

        CREATE OR REPLACE TABLE DEMO3D_DB.PUBLIC.SALES AS
        (SELECT * FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.WEB_SALES)
        LIMIT 100000;


    - Now, we'll run out query directly on the new table:

        SELECT 1 AS INPUT_ITEM, 
               WS_WEB_SITE_SK AS BASKET_ITEM,
               COUNT (DISTINCT WS_ORDER_NUMBER) BASKETS
        FROM DEMO3D_DB.PUBLIC.SALES
        WHERE WS_ORDER_NUMBER IN
          (SELECT WS_ORDER_NUMBER
           FROM DEMO3D_DB.PUBLIC.SALES
           WHERE WS_WEB_SITE_SK = 1)
        GROUP BY WS_WEB_SITE_SK
        ORDER BY 3 DESC, 2;


    - We might be willing to share those kind of related sales details with the manufacturers, but we 
        wouldn't want to allow them to access the underlying data.  To, instead we will provide a secure
        SQL UDF function.

        CREATE OR REPLACE SECURE FUNCTION
            DEMO3D_DB.PUBLIC.GET_MKTBASKET(INPUT_WEB_SITE_SK number(38))
        RETURNS TABLE (INPUT_ITEM NUMBER(38, 0), BASKET_ITEM NUMBER(38, 0), BASKETS NUMBER(38, 0)) AS
            'SELECT input_web_site_sk, 
                    WS_WEB_SITE_SK as BASKET_ITEM,
                    COUNT(DISTINCT WS_ORDER_NUMBER) BASKETS
            FROM DEMO3D_DB.PUBLIC.SALES
            WHERE WS_ORDER_NUMBER IN
                (SELECT WS_ORDER_NUMBER
                 FROM DEMO3D_DB.PUBLIC.SALES
                 WHERE WS_WEB_SITE_SK = input_web_site_sk)
            GROUP BY ws_web_site_sk
            ORDER BY 3 DESC, 2';


    - To call the secure function:

        -- Get items bought with item 1
        SELECT * FROM TABLE(DEMO3D_DB.PUBLIC.GET_MKTBASKET(1));



- Stored Procedures

    - Stored procedures allow you to extend Snowflake SQL by combining it with JS in order to include
        branching, looping, and error handling.  They can only be written in JS at this time.


    - In our first stored procedure example, we'll pass in an argument:

        -- Define stored procedure
        CREATE OR REPLACE DATABASE DEMO3E_DB;

        CREATE OR REPLACE PROCEDURE STOREDPROC1(ARGUMENT1 VARCHAR)
        RETURNS string not null
        language javascript AS
        $$
        var INPUT_ARGUMENT1 = ARGUMENT1;
        var result = `${INPUT_ARGUMENT1}`
        return result;
        $$;

        -- Call the stored procedure
        CALL STOREDPROC1('I really love Snowflake!')



- Example - Stored Procedure for Bank Transactions

    - We are recording the accounting transactions for a bank that deals with customers giving cash to the
        bank and getting cash from the bank.  We'll keep track of deposits, withdrawls, and loan payments.


    - First, we'll create a stored procedure for a deposit transaction in which the bank's cash account is
        debited and the customer account on the bank's balance sheet is credited whenever a customer
        gives the bank cash to add to their account.

        USE ROLE SYSADMIN; USE DATABASE DEMO3A_DB; USE SCHEMA BANKING;
        CREATE OR REPLACE PROCEDURE deposit(PARAM_ACCT FLOAT, PARAM_AMT FLOAT)
        returns STRING LANGUAGE javascript AS
            $$
            var ret_val = ""; var cmd_debit = ""; var cmd_credit = "";

            // INSERT data into tables
            cmd_debit = "INSERT INTO DEMO3A_DB.BANKING.CASH VALUES ("
            + PARAM_ACCT + "," + PARAM_AMT + ",current_timestamp());";

            cmd_credit = "INSERT INTO DEMO3A_DB.BANKING.CUSTOMER_ACCT VALUES ("
            + PARAM_ACCT + "," + PARAM_AMT + ",current_timestamp());";

            // BEGIN transaction
            snowflake.execute ({sqlText: cmd_debit});
            snowflake.execute ({sqlText: cmd_credit});
            ret_val = "Deposit Transaction Succeeded";
            return ret_val;
            $$;


    - Next, we'll create a transaction for a withdrawl, which is just the reverse of a deposit:

        USE ROLE SYSADMIN;USE DATABASE DEMO3A_DB; USE SCHEMA BANKING;
        CREATE OR REPLACE PROCEDURE withdrawal(PARAM_ACCT FLOAT, PARAM_AMT FLOAT)
        returns STRING LANGUAGE javascript AS
            $$
            var ret_val = ""; var cmd_debit = ""; var cmd_credit = "";

            // INSERT data into tables
            cmd_debit = "INSERT INTO DEMO3A_DB.BANKING.CUSTOMER_ACCT VALUES ("
            + PARAM_ACCT + "," + (-PARAM_AMT) + ",current_timestamp());";

            cmd_credit = "INSERT INTO DEMO3A_DB.BANKING.CASH VALUES ("
            + PARAM_ACCT + "," + (-PARAM_AMT) + ",current_timestamp());";

            // BEGIN transaction
            snowflake.execute ({sqlText: cmd_debit});
            snowflake.execute ({sqlText: cmd_credit});
            ret_val = "Withdrawal Transaction Succeeded";
            return ret_val;
            $$;


    - Finally, we'll create a transaction for a loan payment, in which the bank's cash accout is debited
        and the receivables account is credited.

        USE ROLE SYSADMIN;USE DATABASE DEMO3A_DB; USE SCHEMA BANKING;
        CREATE OR REPLACE PROCEDURE loan_payment(PARAM_ACCT FLOAT, PARAM_AMT FLOAT)
        returns STRING LANGUAGE javascript AS
            $$
            var ret_val = ""; var cmd_debit = ""; var cmd_credit = "";

            // INSERT data into the tables
            cmd_debit = "INSERT INTO DEMO3A_DB.BANKING.CASH VALUES ("
            + PARAM_ACCT + "," + PARAM_AMT + ",current_timestamp());";

            cmd_credit = "INSERT INTO DEMO3A_DB.BANKING.RECEIVABLES VALUES ("
            + PARAM_ACCT + "," +(-PARAM_AMT) + ",current_timestamp());";

            //BEGIN transaction
            snowflake.execute ({sqlText: cmd_debit});
            snowflake.execute ({sqlText: cmd_credit});
            ret_val = "Loan Payment Transaction Succeeded";
            return ret_val;
            $$;


    - Now, let's run a few quick tests to see if the procedures are working:

        -- Make transactions
        CALL withdrawl(21, 100);
        CALL loan_payment(21, 100);
        CALL deposit(21, 100);

        -- Review results
        SELECT CUSTOMER_ACCOUNT, AMOUNT FROM DEMO3A_DB.BANKING.CASH;


    - Now, we can truncate the tables, leaving the tables intact, but removing the data:

        USE ROLE SYSADMIN; USE DATABASE DEMO3A_DB; USE SCHEMA BANKING;
        TRUNCATE TABLE DEMO3A_DB.BANKING.CUSTOMER_ACCT;
        TRUNCATE TABLE DEMO3A_DB.BANKING.CASH;
        TRUNCATE TABLE DEMO3A_DB.BANKING.RECEIVABLES;


    - With the tables empty, now we can input some transactions by calling the procedures:

        USE ROLE SYSADMIN;
        CALL deposit(21, 10000);
        CALL deposit(21, 400);
        CALL loan_payment(14, 1000);
        CALL withdrawal(21, 500);
        CALL deposit(72, 4000);
        CALL withdrawal(21, 250);


    - We'd like to see a transaction summary, so we'll call one final stored procedure:

        USE ROLE SYSADMIN; USE DATABASE DEMO3B_DB; USE SCHEMA BANKING;
        CREATE OR REPLACE PROCEDURE Transactions_Summary()
        returns STRING LANGUAGE javascript AS
            $$
            var cmd_truncate = `TRUNCATE TABLE IF EXISTS DEMO3B_DB.BANKING.SUMMARY;`
            var sql = snowflake.createStatement({sqlText: cmd_truncate});

            //Summarize Cash Amount
            var cmd_cash = `Insert into DEMO3B_DB.BANKING.SUMMARY (CASH_AMT)
            select sum(AMOUNT) from DEMO3A_DB.BANKING.CASH;`
            var sql = snowflake.createStatement({sqlText: cmd_cash});

            //Summarize Receivables Amount
            var cmd_receivables = `Insert into DEMO3B_DB.BANKING.SUMMARY
            (RECEIVABLES_AMT) select sum(AMOUNT) from DEMO3A_DB.BANKING.RECEIVABLES;`
            var sql = snowflake.createStatement({sqlText: cmd_receivables});

            //Summarize Customer Account Amount
            var cmd_customer = `Insert into DEMO3B_DB.BANKING.SUMMARY (CUSTOMER_AMT)
            select sum(AMOUNT) from DEMO3A_DB.BANKING.CUSTOMER_ACCT;`
            var sql = snowflake.createStatement({sqlText: cmd_customer});

            //BEGIN transaction
            snowflake.execute ({sqlText: cmd_truncate});
            snowflake.execute ({sqlText: cmd_cash});
            snowflake.execute ({sqlText: cmd_receivables});
            snowflake.execute ({sqlText: cmd_customer});
            ret_val = "Transactions Successfully Summarized";
            return ret_val;
            $$;


    - We'll call our new stored procedure to get the transaction summary:

        -- Call procedure
        CALL Transactions_Summary();

        -- Look at the table
        SELECT * FROM DEMO3B_DB.BANKING.SUMMARY;

        -- Look at the materialized view we created earlier, which has been kept updated
        USE ROLE SYSADMIN; USE DATABASE DEMO3B_DB;USE SCHEMA BANKING;
        SELECT * FROM DEMO3B_DB.BANKING.SUMMARY_MVW;

        -- Look at the nonmaterialized view we created earlier
        USE ROLE SYSADMIN; USE DATABASE DEMO3B_DB;USE SCHEMA BANKING;
        SELECT * FROM DEMO3B_DB.BANKING.SUMMARY_VW;



- Example - Stored Procedure to Delete a Database

    - We'll create a stored procedure to delete a database.  To do this, we'll add a 'task', which can 
        either call a stored procedure or execute a single SQL statement.


    - Obviously, it's important that we put the stored procedure in a different database from the one we
        want to delete.

        USE ROLE SYSADMIN; USE DATABASE DEMO3E_DB;
        CREATE OR REPLACE PROCEDURE drop_db()
        RETURNS STRING NOT NULL LANGUAGE javascript AS
            $$
            var cmd = `DROP DATABASE DEMO3A_DB;`
            var sql = snowflake.createStatement({sqlText: cmd});
            var result = sql.execute();
            return 'Database has been successfully dropped';
            $$;


    - Now we can call the stored procedure and the database will be dropped.  This is part of the cleanup
        for this chapter:

        CALL drop_db();


    - Now, we'll drop the other sample database from this chapter, and we'll add a task to do it 15
        minutes from now.  Here's that stored procedure:

        USE ROLE SYSADMIN;
        CREATE OR REPLACE PROCEDURE drop_db() RETURNS STRING NOT NULL
        LANGUAGE javascript AS
            $$
            var cmd = `DROP DATABASE "DEMO3B_DB";`
            var sql = snowflake.createStatement({sqlText: cmd});
            var result = sql.execute();
            return 'Database has been successfully dropped';
            $$;


    - And here is the task we'll create to execute the stored procedure:

        USE ROLE SYSADMIN; USE DATABASE DEMO3E_DB;
        CREATE OR REPLACE TASK tsk_wait_15
        WAREHOUSE = COMPUTE_WH SCHEDULE = '15 MINUTE'
        AS CALL drop_db();


    - The SYSADMIN role is going to need some privileges to execute the task, so we need to switch to
        ACCOUNTADMIN.  Even though SYSADMIN is the task owner, an elevated account-level privilege to
        execute tasks is required.

        USE ROLE ACCOUNTADMIN;
        GRANT EXECUTE TASK ON ACCOUNT TO ROLE SYSADMIN;


    - We can now set the role to SYSADMIN.  Because tasks are always created in a suspended state, they'll
        need to be resumed.

        USE ROLE SYSADMIN;
        ALTER TASK IF EXISTS tsk_wait_15 RESUME;


    - To check that our task is created and in a scheduled state:

        SELECT * FROM table(information_schema.task_history
            (task_name => 'tsk_wait_15',
            scheduled_time_range_start =>
            dateadd('hour', -1, current_timestamp())));


    - Once we see that the task has been completed and the database has been dropped, we can suspend the
        task:

        USE ROLE SYSADMIN;
        ALTER TASK IF EXISTS tsk_15 SUSPEND;



- Introduction to Pipes, Streams, and Sequences

    - Pipes, streams, and sequences are Snowflake objects.

        - 'Pipes' are objects that contain a COPY command that is used by Snowpipe.  Snowpipe is used for
            continuous, serverless loading of data into a Snowflake target table.

        - 'Streams', aka CDC, keep track of certain changes made to the table, including inserts, updates,
            and deletes.  Streams have many useful purposes, including recording changes made in a
            staging table which are used to update another table.

        - A 'sequence' object is used to generate unique numbers.  Often, sequences are used as surrogate
            keys for primary key values.


    - Here is how we can generate a sequence that begins with 1 and increments by 1:

        -- Generate sequence
        USE ROLE SYSADMIN; USE DATABASE DEMO3E_DB;
        CREATE OR REPLACE SEQUENCE SEQ_01 START = 1 INCREMENT = 1;
        CREATE OR REPLACE TABLE SEQUENCE_TEST(i integer);

        -- Run this query a few times to see increasing values
        SELECT SEQ_01.NEXTVAL;


    - This sequence increments by 2:

        -- Generate sequence
        USE ROLE SYSADMIN;USE DATABASE DEMO3E_DB;
        CREATE OR REPLACE SEQUENCE SEQ_02 START = 1 INCREMENT = 2;
        CREATE OR REPLACE TABLE SEQUENCE_TEST(i integer);

        -- See the increments
        SELECT SEQ_02.NEXTVAL a, SEQ_02.NEXTVAL b,SEQ_02.NEXTVAL c,SEQ_02.NEXTVAL d;


    - Note that sequence values, although unique, are not necessarily free of gaps.  This is because 
        sequences are user-defined and not tied to any specific table.

      An alternative is to create identity columns in which you generate auto-incrementing numbers, often
        used as a PK, in one specific table.



- Snowflake Streams (Deep Dive)

    - A Snowflake stream works like a pointer that keeps track of the status of a DML operation on a defined
        table.  A Snowflake table stream creates a change table that shows what has changed, at a row level,
        between 2 transactional points in time.


    - Streams are like processing queues and can be queried just like a table.  Table streams make it easy
        to grab the new data by taking a snapshot of all the rows in a table at a point in time, and only
        storing an offset for the source table.

      In this way, a stream can return the CDC records by leveraging the versioning history.


    - For an example, we'll create a table for bank branches that stores the branch ID, city, and 
        dollar amount of deposits on a particular day.  We'll create a new database, schema, and table.

        -- Create objects
        USE ROLE SYSADMIN;
        CREATE OR REPLACE DATABASE DEMO3F_DB;
        CREATE OR REPLACE SCHEMA BANKING;
        CREATE OR REPLACE TABLE BRANCH (ID varchar, City varchar, Amount number (20,2));

        -- Insert some data
        INSERT INTO BRANCH (ID, City, Amount)
        values
            (12001, 'Abilene', 5387.97),
            (12002, 'Barstow', 34478.10),
            (12003, 'Cadbury', 8994.63);


    - Now, we'll create 2 streams:

        -- Create streams
        CREATE OR REPLACE STREAM STREAM_A ON TABLE BRANCH;
        CREATE OR REPLACE STREAM STREAM_B ON TABLE BRANCH;

        -- View the streams we created
        SHOW STREAMS;


    - We'll add some more data, and then we can see the CDC records in the streams:

        -- Insert more data
        INSERT INTO BRANCH (ID, City, Amount)
        values
            (12004, 'Denton', 41242.93),
            (12005, 'Everett', 6175.22),
            (12006, 'Fargo', 443689.75);

        -- View the updated table and the streams
        SELECT * FROM BRANCH;
        SELECT * FROM STREAM_A;
        SELECT * FROM STREAM_B;


    - Now, there are 6 records in the BRANCH table, and 3 records each in the STREAM_A and STREAM_B
        tables.  We'll create a new stream, which will have no records at first.  Then, we'll insert some
        more data.

        -- Create new stream
        CREATE OR REPLACE STREAM STREAM_C ON TABLE BRANCH;

        -- Insert more data
        INSERT INTO BRANCH (ID, City, Amount)
        values
            (12007, 'Galveston', 351247.79),
            (12008, 'Houston', 917011.27);

      At this point, BRANCH has 8 records, STREAM_A and STREAM_B each have 5 records, and STREAM_C has 2
        records.


    - If we re-create STREAM_B, all records will be removed, and it will have 0 records:

        CREATE OR REPLACE STREAM STREAM_B ON TABLE BRANCH;


    - To see the impact of deleting records, we'll delete the first record from each of the previous
        inserts:

        DELETE FROM BRANCH WHERE ID = 12001;
        DELETE FROM BRANCH WHERE ID = 12004;
        DELETE FROM BRANCH WHERE ID = 12007;





- Snowflake Tasks (Deep Dive)



- Code Cleanup